{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b85918-4dbe-4969-bb75-f06983d1f778",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Unzip_WWI_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8fc68-ce69-428f-ada2-eff3821289c9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-05-31T14:47:48.8814961Z",
       "execution_start_time": "2025-05-31T14:41:16.2605416Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f9bc38d6-01f0-4248-a9d1-62f0e7c5864e",
       "queued_time": "2025-05-31T14:41:16.2593471Z",
       "session_id": "be030cf0-e990-48e6-bc68-b2807ccca23d",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 9,
       "statement_ids": [
        9
       ]
      },
      "text/plain": [
       "StatementMeta(, be030cf0-e990-48e6-bc68-b2807ccca23d, 9, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Found the zip file. Now attempting to extract...\n",
      "Successfully extracted all files from 'wwi-sample-dataset.zip' to the '/lakehouse/default/Files/imported_files/' folder.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Import necessary libraries\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the directory path and the name of the zip file to be extracted.\n",
    "# This makes it easy to update if the file name or location changes.\n",
    "LAKEHOUSE_FILES_DIR = \"/lakehouse/default/Files/imported_files\"\n",
    "SOURCE_ZIP_NAME = \"wwi-sample-dataset.zip\"\n",
    "\n",
    "# Construct the full paths for the source file and the extraction destination\n",
    "source_file_path = f\"{LAKEHOUSE_FILES_DIR}/{SOURCE_ZIP_NAME}\"\n",
    "destination_path = LAKEHOUSE_FILES_DIR\n",
    "\n",
    "# --- Extraction Process ---\n",
    "print(f\"Starting extraction process for: {SOURCE_ZIP_NAME}\")\n",
    "\n",
    "# Safety check: Ensure the source file actually exists before proceeding.\n",
    "if os.path.exists(source_file_path):\n",
    "    # The 'with' statement ensures the file is properly closed after use.\n",
    "    with zipfile.ZipFile(source_file_path, 'r') as zip_archive:\n",
    "        # Extract all contents of the zip archive to the destination folder.\n",
    "        zip_archive.extractall(path=destination_path)\n",
    "    \n",
    "    print(f\"Success: Data extracted to {destination_path}\")\n",
    "else:\n",
    "    print(f\"ERROR: Source file not found at {source_file_path}. Please check the path and filename.\")"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "1d62eec1-4ae3-45d3-85c6-befa936564dc",
    "default_lakehouse_name": "medium1",
    "default_lakehouse_workspace_id": "d5e083f9-01a0-4b3f-a56c-f6863c0382a3",
    "known_lakehouses": [
     {
      "id": "1d62eec1-4ae3-45d3-85c6-befa936564dc"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
